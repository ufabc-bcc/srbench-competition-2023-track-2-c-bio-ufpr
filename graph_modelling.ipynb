{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric as pyG\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# utils\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Berri1</th>\n",
       "      <th>Boyer</th>\n",
       "      <th>Brébeuf</th>\n",
       "      <th>CSC (Côte Sainte-Catherine)</th>\n",
       "      <th>Maisonneuve_2</th>\n",
       "      <th>Maisonneuve_3</th>\n",
       "      <th>Notre-Dame</th>\n",
       "      <th>Parc</th>\n",
       "      <th>PierDup</th>\n",
       "      <th>Rachel / Hôtel de Ville</th>\n",
       "      <th>Rachel / Papineau</th>\n",
       "      <th>René-Lévesque</th>\n",
       "      <th>Saint-Antoine</th>\n",
       "      <th>Saint-Urbain</th>\n",
       "      <th>Totem_Laurier</th>\n",
       "      <th>University</th>\n",
       "      <th>Viger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2015</td>\n",
       "      <td>00:00</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>78</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/01/2015</td>\n",
       "      <td>00:00</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>113</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>109</td>\n",
       "      <td>177</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>57</td>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/01/2015</td>\n",
       "      <td>00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>131</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>174</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/01/2015</td>\n",
       "      <td>00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/01/2015</td>\n",
       "      <td>00:00</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>11/11/2015</td>\n",
       "      <td>00:00</td>\n",
       "      <td>3044</td>\n",
       "      <td>1931</td>\n",
       "      <td>2828</td>\n",
       "      <td>1393</td>\n",
       "      <td>3603</td>\n",
       "      <td>1754</td>\n",
       "      <td>1142</td>\n",
       "      <td>2342</td>\n",
       "      <td>458</td>\n",
       "      <td>2328</td>\n",
       "      <td>3280</td>\n",
       "      <td>1210</td>\n",
       "      <td>338</td>\n",
       "      <td>1534</td>\n",
       "      <td>1527</td>\n",
       "      <td>2860</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>12/11/2015</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1751</td>\n",
       "      <td>930</td>\n",
       "      <td>1670</td>\n",
       "      <td>888</td>\n",
       "      <td>2048</td>\n",
       "      <td>700</td>\n",
       "      <td>675</td>\n",
       "      <td>1566</td>\n",
       "      <td>152</td>\n",
       "      <td>1345</td>\n",
       "      <td>1877</td>\n",
       "      <td>755</td>\n",
       "      <td>180</td>\n",
       "      <td>960</td>\n",
       "      <td>955</td>\n",
       "      <td>1777</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>13/11/2015</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1818</td>\n",
       "      <td>906</td>\n",
       "      <td>1711</td>\n",
       "      <td>873</td>\n",
       "      <td>2115</td>\n",
       "      <td>634</td>\n",
       "      <td>477</td>\n",
       "      <td>1522</td>\n",
       "      <td>150</td>\n",
       "      <td>1416</td>\n",
       "      <td>1980</td>\n",
       "      <td>719</td>\n",
       "      <td>204</td>\n",
       "      <td>978</td>\n",
       "      <td>1040</td>\n",
       "      <td>1727</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>14/11/2015</td>\n",
       "      <td>00:00</td>\n",
       "      <td>979</td>\n",
       "      <td>759</td>\n",
       "      <td>978</td>\n",
       "      <td>322</td>\n",
       "      <td>1112</td>\n",
       "      <td>290</td>\n",
       "      <td>310</td>\n",
       "      <td>601</td>\n",
       "      <td>98</td>\n",
       "      <td>1061</td>\n",
       "      <td>1448</td>\n",
       "      <td>269</td>\n",
       "      <td>70</td>\n",
       "      <td>640</td>\n",
       "      <td>805</td>\n",
       "      <td>737</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>15/11/2015</td>\n",
       "      <td>00:00</td>\n",
       "      <td>913</td>\n",
       "      <td>749</td>\n",
       "      <td>1028</td>\n",
       "      <td>348</td>\n",
       "      <td>1128</td>\n",
       "      <td>303</td>\n",
       "      <td>224</td>\n",
       "      <td>666</td>\n",
       "      <td>224</td>\n",
       "      <td>1094</td>\n",
       "      <td>1491</td>\n",
       "      <td>321</td>\n",
       "      <td>64</td>\n",
       "      <td>537</td>\n",
       "      <td>804</td>\n",
       "      <td>685</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   Time  Berri1  Boyer  Brébeuf  CSC (Côte Sainte-Catherine)   \n",
       "0    01/01/2015  00:00      58     12        4                           17  \\\n",
       "1    02/01/2015  00:00      75      7        5                           15   \n",
       "2    03/01/2015  00:00      79      7        3                            7   \n",
       "3    04/01/2015  00:00      10      1       21                            0   \n",
       "4    05/01/2015  00:00      42      0        2                            0   \n",
       "..          ...    ...     ...    ...      ...                          ...   \n",
       "314  11/11/2015  00:00    3044   1931     2828                         1393   \n",
       "315  12/11/2015  00:00    1751    930     1670                          888   \n",
       "316  13/11/2015  00:00    1818    906     1711                          873   \n",
       "317  14/11/2015  00:00     979    759      978                          322   \n",
       "318  15/11/2015  00:00     913    749     1028                          348   \n",
       "\n",
       "     Maisonneuve_2  Maisonneuve_3  Notre-Dame  Parc  PierDup   \n",
       "0               49             21          16    16        7  \\\n",
       "1              113             27           9    32       11   \n",
       "2              107             36          12    18        2   \n",
       "3               35             29           1     0        0   \n",
       "4               90             21           1     1        6   \n",
       "..             ...            ...         ...   ...      ...   \n",
       "314           3603           1754        1142  2342      458   \n",
       "315           2048            700         675  1566      152   \n",
       "316           2115            634         477  1522      150   \n",
       "317           1112            290         310   601       98   \n",
       "318           1128            303         224   666      224   \n",
       "\n",
       "     Rachel / Hôtel de Ville  Rachel / Papineau  René-Lévesque  Saint-Antoine   \n",
       "0                         58                 91             24              3  \\\n",
       "1                        109                177             32             13   \n",
       "2                         71                131             33              5   \n",
       "3                          6                 11              6              1   \n",
       "4                          0                  5             49             20   \n",
       "..                       ...                ...            ...            ...   \n",
       "314                     2328               3280           1210            338   \n",
       "315                     1345               1877            755            180   \n",
       "316                     1416               1980            719            204   \n",
       "317                     1061               1448            269             70   \n",
       "318                     1094               1491            321             64   \n",
       "\n",
       "     Saint-Urbain  Totem_Laurier  University  Viger  \n",
       "0              17             78          21      6  \n",
       "1              11             57          77      4  \n",
       "2              14            174          40      5  \n",
       "3               1             20           6      0  \n",
       "4               0             41          56     10  \n",
       "..            ...            ...         ...    ...  \n",
       "314          1534           1527        2860    356  \n",
       "315           960            955        1777    198  \n",
       "316           978           1040        1727    258  \n",
       "317           640            805         737     73  \n",
       "318           537            804         685     63  \n",
       "\n",
       "[319 rows x 19 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load bike dataset from datasets folder\n",
    "bike_data = pd.read_csv('datasets/MontrealBikeLane.csv')\n",
    "# removing columns that have any missing data\n",
    "bike_data = bike_data.dropna(axis=1)\n",
    "bike_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Berri1': 0,\n",
       " 'Boyer': 1,\n",
       " 'Brébeuf': 2,\n",
       " 'CSC (Côte Sainte-Catherine)': 3,\n",
       " 'Maisonneuve_2': 4,\n",
       " 'Maisonneuve_3': 5,\n",
       " 'Notre-Dame': 6,\n",
       " 'Parc': 7,\n",
       " 'PierDup': 8,\n",
       " 'Rachel / Hôtel de Ville': 9,\n",
       " 'Rachel / Papineau': 10,\n",
       " 'René-Lévesque': 11,\n",
       " 'Saint-Antoine': 12,\n",
       " 'Saint-Urbain': 13,\n",
       " 'Totem_Laurier': 14,\n",
       " 'University': 15,\n",
       " 'Viger': 16}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionary with column names and index order starting from 0 excluding Date and Time\n",
    "# this is because we want to predict the number of bikes in the future\n",
    "# and we don't want to include the future in our features\n",
    "node_encoder = {}\n",
    "for i, col in enumerate(bike_data.columns):\n",
    "    if col != 'Date' and col != 'Time':\n",
    "        node_encoder[col] = i - 2\n",
    "node_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[17, 1], edge_index=[2, 27])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the BikeLanesConnections.txt and extract the connections between the nodes via links in the PyG format.\n",
    "# Use the previous function of node enconder to transforms bike lanes name to the desired encoded format.\n",
    "# Path: BikeLanesConnections.txt, format X <-> Y\n",
    "# X and Y are the names of the bike lanes\n",
    "# X <-> Y means that X and Y are connected\n",
    "def get_edge_connections():\n",
    "    with open('BikeLanesConnections.txt') as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    content = [x.split(' <-> ') for x in content]\n",
    "    content = [[node_encoder[x[0]], node_encoder[x[1]]] for x in content]\n",
    "    content = torch.tensor(content).t().contiguous()\n",
    "    return content\n",
    "\n",
    "# create function to get edge and node index\n",
    "def get_node_and_edge_index(bike_data):\n",
    "    node_index = list(\n",
    "        range(0, len(\n",
    "                    [col for col in bike_data.columns if col not in [\"Date\", \"Time\"]]\n",
    "                )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    edge_index = get_edge_connections()\n",
    "\n",
    "    return node_index, edge_index\n",
    "\n",
    "# create function to create a Data object in Pytorch Geometric for each row\n",
    "def create_graph(row, edge_index):\n",
    "    node_features = torch.tensor(\n",
    "        row[[col for col in bike_data.columns if col not in [\"Date\", \"Time\"]]],\n",
    "        dtype=torch.float\n",
    "    ).view(-1, 1)\n",
    "    return Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "# showcasing one graph\n",
    "node_index, edge_index = get_node_and_edge_index(bike_data)\n",
    "graph = create_graph(bike_data.iloc[0], edge_index)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251342/665288698.py:6: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  sampled_nodes = random.sample(g.nodes, n_sample)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_to_networkx(graph, n_sample=None):\n",
    "    g = to_networkx(graph, node_attrs=[\"x\"])\n",
    "    y = graph.x.numpy()\n",
    "\n",
    "    if n_sample is not None:\n",
    "        sampled_nodes = random.sample(g.nodes, n_sample)\n",
    "        g = g.subgraph(sampled_nodes)\n",
    "        y = y[sampled_nodes]\n",
    "\n",
    "    return g, y\n",
    "\n",
    "\n",
    "def plot_graph(g, y):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    nx.draw_spring(g, node_size=30, arrows=False, node_color=y)\n",
    "    plt.show() \n",
    "    \n",
    "    \n",
    "g, y = convert_to_networkx(graph, n_sample=17)\n",
    "plot_graph(g, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new random split.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[17, 1], edge_index=[2, 27], train_mask=[17], val_mask=[17], test_mask=[17])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandomNodeSplitter:\n",
    "    def __init__(self, train_val_test_ratio = [0.8, 0.1, 0.1]):\n",
    "        self.train_val_test_ratio = train_val_test_ratio\n",
    "        self.has_mask = False\n",
    "    \n",
    "\n",
    "    def setup_split(self, num_nodes) -> None:\n",
    "        num_nodes = graph.num_nodes\n",
    "        train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "        # randomly assign nodes to train, val, test with permutation\n",
    "        train_ratio = self.train_val_test_ratio[0]\n",
    "        train_n = int(num_nodes * train_ratio)\n",
    "        val_ratio = self.train_val_test_ratio[1]\n",
    "        val_n = int(num_nodes * val_ratio)\n",
    "\n",
    "        permutation = torch.randperm(num_nodes)\n",
    "        train_mask[permutation[:train_n]] = 1\n",
    "        val_mask[permutation[train_n:train_n+val_n]] = 1\n",
    "        test_mask[permutation[train_n+val_n:]] = 1\n",
    "\n",
    "        self.train_mask = train_mask\n",
    "        self.val_mask = val_mask\n",
    "        self.test_mask = test_mask\n",
    "\n",
    "        self.has_mask = True\n",
    "\n",
    "\n",
    "    def __call__(self, graph, save_mask=True) -> pyG.data.data.Data:\n",
    "        if self.has_mask is False or save_mask is False:\n",
    "            print(\"Generating new random split.\")\n",
    "            self.setup_split(graph.num_nodes)\n",
    "\n",
    "        # assign masks to graph\n",
    "        graph.train_mask = self.train_mask\n",
    "        graph.val_mask = self.val_mask\n",
    "        graph.test_mask = self.test_mask\n",
    "\n",
    "        return graph\n",
    "\n",
    "split = RandomNodeSplitter()\n",
    "graph = split(graph)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[5423, 1], edge_index=[2, 8613], train_mask=[5423], val_mask=[5423], test_mask=[5423], batch=[5423], ptr=[320])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using loader to get the full dataset but split into train, val, test\n",
    "split = RandomNodeSplitter()\n",
    "split.setup_split(graph.num_nodes)\n",
    "data_list = [split(create_graph(row, edge_index)) for _, row in bike_data.iterrows()]\n",
    "loader = DataLoader(data_list, batch_size=len(data_list), shuffle=False)\n",
    "for dataset in loader:\n",
    "    break\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Networks (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss train: 432.2086. Validation loss: 115.3189: 100%|██████████| 100000/100000 [13:20<00:00, 124.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2188.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# def eval_node_regression(model, graph, mask):\n",
    "#     model.eval()\n",
    "#     pred = model(graph)\n",
    "#     return F.mse_loss(pred[mask], graph.x[mask])\n",
    "\n",
    "# def train_node_regression(model, graph, optimizer, criterion, n_epochs=200):\n",
    "#     pbar = tqdm(range(1, n_epochs + 1))\n",
    "#     for epoch in pbar:\n",
    "#         model.train()\n",
    "#         optimizer.zero_grad()\n",
    "#         out = model(graph)\n",
    "#         loss = criterion(out[graph.train_mask], graph.x[graph.train_mask])\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         reg_loss = eval_node_regression(model, graph, graph.val_mask)\n",
    "\n",
    "#         # use pbar to print loss every 1% of the training\n",
    "#         if epoch % (n_epochs // 100) == 0:\n",
    "#             pbar.set_description(f\"Loss train: {loss.item():.4f}. Validation loss: {reg_loss:.4f}\")\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "# class GCN(torch.nn.Module):\n",
    "#     def __init__(self, num_node_features:int, dim_last_layer:int):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = GCNConv(num_node_features, 1)\n",
    "#         self.conv2 = GCNConv(1, 1)\n",
    "#         self.conv3 = GCNConv(1, 1)\n",
    "#         self.fc1 = nn.Linear(1, dim_last_layer)\n",
    "\n",
    "#     def forward(self, graph):\n",
    "#         x, edge_index = graph.x, graph.edge_index\n",
    "#         h = self.conv1(x, edge_index)\n",
    "#         h = h.tanh()\n",
    "#         h = self.conv2(h, edge_index)\n",
    "#         h = h.tanh()\n",
    "#         h = self.conv3(h, edge_index)\n",
    "#         h = h.tanh()  # Final GNN embedding space.\n",
    "        \n",
    "#         # Apply a final (linear) layer\n",
    "#         out = self.fc1(h)\n",
    "\n",
    "#         return out\n",
    "    \n",
    "# device = \"cpu\"\n",
    "# graph = dataset[0]\n",
    "# gcn = GCN(dataset.num_features, 1)\n",
    "# optimizer_gcn = torch.optim.Adam(gcn.parameters(), lr=0.001)\n",
    "# criterion = nn.MSELoss()\n",
    "# gcn = train_node_regression(gcn, graph, optimizer_gcn, criterion, n_epochs=100000)\n",
    "\n",
    "# test_loss = eval_node_regression(gcn, graph, graph.test_mask)\n",
    "# print(f'Test loss: {test_loss:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.loader import LinkNeighborLoader\n",
    "# from torch_geometric.nn import GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = graph\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = GraphSAGE(data.num_node_features, hidden_channels=64,\n",
    "#                   num_layers=2).to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# x, edge_index = data.x.to(device), data.edge_index.to(device)\n",
    "\n",
    "# train_loader = LinkNeighborLoader(\n",
    "#     data,\n",
    "#     batch_size=10,\n",
    "#     shuffle=True,\n",
    "#     neg_sampling_ratio=1.0,\n",
    "#     num_neighbors=[10, 10],\n",
    "# )\n",
    "\n",
    "\n",
    "# def train():\n",
    "#     model.train()\n",
    "\n",
    "#     total_loss = 0\n",
    "#     for batch in train_loader:\n",
    "#         print(batch)\n",
    "#         raise Exception\n",
    "#         batch = batch.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         h = model(batch.x, batch.edge_index)\n",
    "#         h_src = h[batch.edge_label_index[0]]\n",
    "#         h_dst = h[batch.edge_label_index[1]]\n",
    "#         pred = (h_src * h_dst).sum(dim=-1)\n",
    "#         loss = F.binary_cross_entropy_with_logits(pred, batch.edge_label)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += float(loss) * pred.size(0)\n",
    "\n",
    "#     return total_loss / data.num_nodes\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def test():\n",
    "#     model.eval()\n",
    "#     out = model(data.x.to(device), data.edge_index.to(device)).cpu()\n",
    "\n",
    "#     clf = LogisticRegression()\n",
    "#     clf.fit(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "#     val_acc = clf.score(out[data.val_mask], data.y[data.val_mask])\n",
    "#     test_acc = clf.score(out[data.test_mask], data.y[data.test_mask])\n",
    "\n",
    "#     return val_acc, test_acc\n",
    "\n",
    "\n",
    "# for epoch in range(1, 51):\n",
    "#     loss = train()\n",
    "#     val_acc, test_acc = test()\n",
    "#     print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "#           f'Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Message Passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[17, 1], edge_index=[2, 27], train_mask=[17], val_mask=[17], test_mask=[17])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss train: 654.2180. Validation loss: 26.7605:   6%|▌         | 564/10000 [00:03<00:57, 163.20it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m optimizer_gcn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(gcn\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m     75\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[0;32m---> 76\u001b[0m gcn \u001b[39m=\u001b[39m train_node_regression(gcn, graph, optimizer_gcn, criterion, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m)\n\u001b[1;32m     78\u001b[0m test_loss \u001b[39m=\u001b[39m eval_node_regression(gcn, graph, graph\u001b[39m.\u001b[39mtest_mask)\n\u001b[1;32m     79\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest loss: \u001b[39m\u001b[39m{\u001b[39;00mtest_loss\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[38], line 57\u001b[0m, in \u001b[0;36mtrain_node_regression\u001b[0;34m(model, graph, optimizer, criterion, n_epochs)\u001b[0m\n\u001b[1;32m     54\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     55\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 57\u001b[0m reg_loss \u001b[39m=\u001b[39m eval_node_regression(model, graph, graph\u001b[39m.\u001b[39;49mval_mask)\n\u001b[1;32m     59\u001b[0m \u001b[39m# use pbar to print loss every 1% of the training\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m (n_epochs \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m100\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[38], line 44\u001b[0m, in \u001b[0;36meval_node_regression\u001b[0;34m(model, graph, mask)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval_node_regression\u001b[39m(model, graph, mask):\n\u001b[1;32m     43\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> 44\u001b[0m     pred \u001b[39m=\u001b[39m  model(graph\u001b[39m.\u001b[39;49mx, graph\u001b[39m.\u001b[39;49medge_index)\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mmse_loss(pred[mask], graph\u001b[39m.\u001b[39mx[mask])\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/srbench-competition-2023-track-2-c-bio-ufp-hz3D8iXw-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[38], line 31\u001b[0m, in \u001b[0;36mGNN.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index):\n\u001b[1;32m     30\u001b[0m     \u001b[39m# x is [n, num_features]; edge_index is [2, E]\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/srbench-competition-2023-track-2-c-bio-ufp-hz3D8iXw-py3.10/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:467\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m         msg_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 467\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmsg_kwargs)\n\u001b[1;32m    468\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    469\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (msg_kwargs, ), out)\n",
      "Cell \u001b[0;32mIn[38], line 35\u001b[0m, in \u001b[0;36mGNN.message\u001b[0;34m(self, x_i, x_j)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmessage\u001b[39m(\u001b[39mself\u001b[39m, x_i, x_j):\n\u001b[1;32m     34\u001b[0m     \u001b[39m# x_i has shape [E, num_features]; x_j has shape [E, num_features]\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmsg_fnc(x_j)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/srbench-competition-2023-track-2-c-bio-ufp-hz3D8iXw-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/srbench-competition-2023-track-2-c-bio-ufp-hz3D8iXw-py3.10/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/srbench-competition-2023-track-2-c-bio-ufp-hz3D8iXw-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/srbench-competition-2023-track-2-c-bio-ufp-hz3D8iXw-py3.10/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.nn import MetaLayer, MessagePassing\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "\n",
    "\n",
    "class GNN(MessagePassing):\n",
    "    def __init__(self, num_features, msg_dim, node_embed_dim, hidden=16, aggr='add'):\n",
    "        super(GNN, self).__init__(aggr=aggr)\n",
    "        self.msg_fnc = Seq(\n",
    "            Lin(num_features, hidden),\n",
    "            ReLU(),\n",
    "            Lin(hidden, hidden),\n",
    "            ReLU(),\n",
    "            Lin(hidden, msg_dim)\n",
    "        )\n",
    "        \n",
    "        self.node_fnc = Seq(\n",
    "            Lin(msg_dim, hidden),\n",
    "            ReLU(),\n",
    "            Lin(hidden, hidden),\n",
    "            ReLU(),\n",
    "            Lin(hidden, node_embed_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # x is [n, num_features]; edge_index is [2, E]\n",
    "        return self.propagate(edge_index, x=x)\n",
    "      \n",
    "    def message(self, x_i, x_j):\n",
    "        # x_i has shape [E, num_features]; x_j has shape [E, num_features]\n",
    "        return self.msg_fnc(x_j)\n",
    "    \n",
    "    def update(self, aggr_out, x=None):\n",
    "        # aggr_out has shape [n, msg_dim]\n",
    "        return self.node_fnc(aggr_out) #[n, node_embed_dim]\n",
    "    \n",
    "\n",
    "def eval_node_regression(model, graph, mask):\n",
    "    model.eval()\n",
    "    pred =  model(graph.x, graph.edge_index)\n",
    "    return F.mse_loss(pred[mask], graph.x[mask])\n",
    "\n",
    "def train_node_regression(model, graph, optimizer, criterion, n_epochs=200):\n",
    "    pbar = tqdm(range(1, n_epochs + 1))\n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "        loss = criterion(out[graph.train_mask], graph.x[graph.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        reg_loss = eval_node_regression(model, graph, graph.val_mask)\n",
    "\n",
    "        # use pbar to print loss every 1% of the training\n",
    "        if epoch % (n_epochs // 100) == 0:\n",
    "            pbar.set_description(f\"Loss train: {loss.item():.4f}. Validation loss: {reg_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "    \n",
    "device = \"cpu\"\n",
    "graph = dataset[0]\n",
    "gcn = GNN(\n",
    "    num_features=dataset.num_features,\n",
    "    msg_dim=16,\n",
    "    node_embed_dim=1,\n",
    "    hidden=32\n",
    ")\n",
    "optimizer_gcn = torch.optim.Adam(gcn.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "gcn = train_node_regression(gcn, graph, optimizer_gcn, criterion, n_epochs=10000)\n",
    "\n",
    "test_loss = eval_node_regression(gcn, graph, graph.test_mask)\n",
    "print(f'Test loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 64])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(graph.x, graph.edge_index).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srbench-competition-2023-track-2-c-bio-ufp-mih08Q5e-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
